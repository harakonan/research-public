\documentclass[11pt]{article}

\usepackage[top=25truemm,bottom=25truemm,left=25truemm,right=25truemm]{geometry}
\geometry{a4paper}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{bbm}
\usepackage{mathtools}
\allowdisplaybreaks

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}

\DeclareMathOperator*{\plim}{plim}
\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\cov}{cov}
\DeclareMathOperator*{\corr}{corr}

\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbbm{1}}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}

\title{Topics on R\\Example R Codes} 
\author{Konan Hara\footnote{Department of Economics, University of Arizona. E-mail: harakonan@email.arizona.edu}}
\date{September 8, 2021}
\begin{document}

\maketitle{}

<<setup, include=FALSE>>=
# Include preliminaries here
opts_chunk$set(fig.height = 5, fig.width = 5)

@

\section{Getting Help}

<<>>=

help(matrix)
example(matrix)
help.search("linearmodels")
help(package="sandwich")

@

\section{R Objects}

\subsection{Numerics, Characters, Logicals, and Factors}

<<>>=

# numeric
n <- 100
class(n)

# numeric
c <- "Konan"
class(c)

# logical
class(TRUE)
class(FALSE)
class(T)
class(F)
as.numeric(TRUE)
as.numeric(FALSE)

# factor
sample_num <- rbinom(10,1,0.5)
sample_num
sample_factor <- factor(sample_num
	, levels = c(0,1)
	, labels = c("control","treatment"))
sample_factor
class(sample_factor)

@

\subsection{Vectors}

<<>>=

# define a vector
v <- c(seq(from = 1, to = 5, by = 1))
v
class(v)

# recycle rule
c(seq(1,3)) + c(seq(1,4))
c(seq(1,2)) + c(seq(1,4))

# operations are vectorized
v <- 1:5
v
sqrt(v)

@

\subsection{Matrices}

<<>>=

# define a matrix
m <- matrix(1:4, nrow = 2, ncol = 2)
m
class(m)

# transpose
t(m)

# dimension
dim(m)

# length
length(m)

# indexing
m[2,1]
m[2,]
m[,1]

@

\subsection{Lists}

<<>>=

# define a list
l <- list(v,m,c("Tiemen","Konan"))
l
class(l)

# element-wise calculation
set.seed(100)
l <- list(rnorm(2), runif(4), rgamma(6,1,1))
l
lapply(l, mean)

@

\subsection{Data Frames}

<<>>=

# define a data.frame
df <- data.frame(
	  V1 = rep(c(1, 2), 5)[-10]
	, V2 = 1:9
	, V3 = c(0.5, 1.0, 1.5)
	, V4 = rep(LETTERS[1:3], 3)
	)
df

# define a data.table
# install.packages("data.table")
library(data.table)
dt <- data.table(
	  V1 = rep(c(1, 2), 5)[-10]
	, V2 = 1:9
	, V3 = c(0.5, 1.0, 1.5)
	, V4 = rep(LETTERS[1:3], 3)
	)
dt

# define a tibble
# install.packages("dplyr")
# dplyr is a part of the "tidyverse"
library(dplyr)
# V3 way doesn't work in tibble
tib <- tibble(
	  V1 = rep(c(1, 2), 5)[-10]
	, V2 = 1:9
	, V3 = c(0.5, 1.0, 1.5)
	, V4 = rep(LETTERS[1:3], 3)
	)
tib <- tibble(
	  V1 = rep(c(1, 2), 5)[-10]
	, V2 = 1:9
	, V3 = rep(c(0.5, 1.0, 1.5), 3)
	, V4 = rep(LETTERS[1:3], 3)
	)
tib

# demo using the R built-in iris data set
# data.frame
head(iris)

# data.table
iris_dt <- as.data.table(iris)
iris_dt

# tibble
iris_tib <- as_tibble(iris)
iris_tib

# summary statistics
# data.frame way
summary(iris)

# data.table way
iris_dt[, .(
	  count = .N
	, mean_sep = mean(Sepal.Length)
	, mean_pet = mean(Petal.Length)
	), by = .(Species)]

# tibble way
iris_tib %>%
	group_by(Species) %>%
	summarise(
		  count = n()
		, mean_sep = mean(Sepal.Length)
		, mean_pet = mean(Petal.Length)
		)

@

\section{Loops}

<<>>=

# for loop
x <- seq(3,7,2)
for (i in x){
	print(i^2)
}

# while loop
i <- 3
while(i <= 7){
	print(i^2)
	i <- i+2
}

# repeat loop
i <- 3
repeat{
	print(i^2)
	i <- i+2
	if(i > 7){
		break
	}
}

@

\section{Regressions}

We replicate Keizer et al. (2008)'s dataset based on the following information:
\begin{itemize}
\item $N_{X=0} = N_{X=1} = 77$;
\item $\bar{Y}_{X=0} = 0.33$ and $\bar{Y}_{X=1} = 0.69$.
\end{itemize}

<<>>=

# use Keizer et al. (2008)'s dataset
keizer_data <- data.table(
	  x = c(rep(0,77), rep(1,77))
	, y = c(rep(1,25), rep(0,52), rep(1,53), rep(0,24))
	)

# linear model
keizer_lm <- lm(formula = y~x, data = keizer_data)

# summary
summary(keizer_lm)

# attributes
attributes(keizer_lm)

# two ways to get coefficients
keizer_lm$coefficients
coefficients(keizer_lm)

# heteroskedasticity robust standard errors
# install.packages("sandwich")
library(sandwich)
# White's estimator
keizer_lm_vcm <- vcovHC(keizer_lm, type = "HC0")
sqrt(diag(keizer_lm_vcm))
# Long & Ervin (2000)
keizer_lm_vcm <- vcovHC(keizer_lm, type = "HC3")
sqrt(diag(keizer_lm_vcm))

# Logit model
keizer_logit <- glm(
	  y~x
	, family = binomial(link = "logit")
	, data = keizer_data
	)

# summary
summary(keizer_logit)

# attributes
attributes(keizer_logit)

@

\section{Plots}

<<>>=

# example data
N <- 1000
data <- data.table(
	  u = rnorm(N)
	, x = rnorm(N)
	)
data[, y := 2.5-0.25*x+u]

# base style
plot(data$x,data$y)
abline(lm(y~x, data=data))

# ggplot style
# install.packages("ggplot")
library(ggplot2)
ggplot(data, aes(x=x, y=y)) +
	geom_point() +
	stat_smooth(formula=y~x, method=lm)

@

\section{User-defined Functions and Optimization}

We estimate the following model:
\begin{enumerate}
\item Data generating process is half $exp(0.5)$ and half $exp(0.75)$.
\item Our model is $y_i \text{ i.i.d.} \sim exp(\theta)$.
\item Estimate $\theta$ by MLE:
\begin{itemize}
\item Log-likelihood: $L(\theta; y_1,\dots,y_N) = N \log(\theta)-\theta \sum_{i=1}^N y_i $
\item Estimator for s.e.: $se(\theta) = \sqrt{\frac{\theta^2}{N}} $
\end{itemize}
\end{enumerate}

<<>>=

# log-likelihood function
# inputs
# y: vector of samples
# theta: parameter
ll_func <- function(y, theta){
	N <- length(y)
	val <- N*log(theta)-theta*sum(y)
	return(val)
}

# example data
theta1 <- 0.5
theta2 <- 0.75
N <- 1000
y1 <- rexp(0.5*N, rate = theta1)
y2 <- rexp(0.5*N, rate = theta2)
y <- c(y1, y2)

# optimization
ll_op <- optimize(
	  ll_func
	, interval = c(0.1,10)
	, y = y
	, maximum = TRUE
	)
ll_op

# estimate for theta
theta_hat <- ll_op$maximum
theta_hat

# estimate for s.e.
sqrt(theta_hat^2/N)

@

\end{document}





















